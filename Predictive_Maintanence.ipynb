{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lq304__bszXi",
        "outputId": "211aa460-5de7-4075-93fd-6118b4cca88d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Model: {'classifier': GradientBoostingClassifier(), 'classifier__learning_rate': 0.01, 'classifier__max_depth': 5, 'classifier__n_estimators': 200}\n",
            "Best Cross-Validation Score: 0.9821250000000001\n",
            "Test Accuracy: 0.983\n",
            "Classification Report:\n",
            "                           precision    recall  f1-score   support\n",
            "\n",
            "Heat Dissipation Failure       0.93      0.93      0.93        15\n",
            "              No Failure       0.99      1.00      0.99      1935\n",
            "      Overstrain Failure       0.70      0.54      0.61        13\n",
            "           Power Failure       0.79      0.75      0.77        20\n",
            "         Random Failures       0.00      0.00      0.00         6\n",
            "       Tool Wear Failure       0.00      0.00      0.00        11\n",
            "\n",
            "                accuracy                           0.98      2000\n",
            "               macro avg       0.57      0.54      0.55      2000\n",
            "            weighted avg       0.97      0.98      0.98      2000\n",
            "\n",
            "Confusion Matrix:\n",
            " [[  14    1    0    0    0    0]\n",
            " [   0 1930    1    4    0    0]\n",
            " [   0    6    7    0    0    0]\n",
            " [   1    3    1   15    0    0]\n",
            " [   0    6    0    0    0    0]\n",
            " [   0   10    1    0    0    0]]\n",
            "Model saved to best_predictive_maintenance_model.joblib\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from joblib import dump, load\n",
        "\n",
        "# Step 1: Load the dataset\n",
        "# Replace 'your_dataset.csv' with your actual dataset file path\n",
        "df = pd.read_csv('/content/drive/MyDrive/Dataset/predictive_maintenance.csv')\n",
        "\n",
        "# Step 2: Data Preprocessing\n",
        "# Separate the target columns and features (Drop UID and Product ID)\n",
        "X = df.drop(columns=['UDI', 'Product ID', 'Target', 'Failure Type'])  # Dropping UID, Product ID, and Target\n",
        "y = df['Failure Type']  # Using 'Failure Type' as the label for prediction\n",
        "\n",
        "# Define numerical columns (you can adjust the columns as needed)\n",
        "numerical_cols = ['Air temperature [K]', 'Process temperature [K]', 'Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]']\n",
        "# No categorical columns to encode in this dataset\n",
        "categorical_cols = []\n",
        "\n",
        "# Preprocessing for numerical data: StandardScaler for scaling\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numerical_cols)\n",
        "    ])\n",
        "\n",
        "# Step 3: Define Models\n",
        "# Try a few different models in the pipeline\n",
        "models = [\n",
        "    ('RandomForest', RandomForestClassifier()),\n",
        "    ('GradientBoosting', GradientBoostingClassifier()),\n",
        "    ('LogisticRegression', LogisticRegression())\n",
        "]\n",
        "\n",
        "# Set up the pipeline with the preprocessor and placeholder for the classifier\n",
        "pipe = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', models[0][1])])\n",
        "\n",
        "# Define parameter grid for hyperparameter tuning\n",
        "param_grid = [\n",
        "    {\n",
        "        'classifier': [RandomForestClassifier()],\n",
        "        'classifier__n_estimators': [50, 100, 200],\n",
        "        'classifier__max_depth': [None, 10, 20]\n",
        "    },\n",
        "    {\n",
        "        'classifier': [GradientBoostingClassifier()],\n",
        "        'classifier__learning_rate': [0.01, 0.1, 0.2],\n",
        "        'classifier__n_estimators': [50, 100, 200],\n",
        "        'classifier__max_depth': [3, 5, 10]\n",
        "    },\n",
        "    {\n",
        "        'classifier': [LogisticRegression(max_iter=200)],\n",
        "        'classifier__C': [0.1, 1.0, 10.0]\n",
        "    }\n",
        "]\n",
        "\n",
        "# Step 4: Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 5: Hyperparameter Tuning with GridSearchCV\n",
        "grid_search = GridSearchCV(pipe, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Step 6: Best model and evaluation\n",
        "best_model = grid_search.best_estimator_\n",
        "print(\"Best Model:\", grid_search.best_params_)\n",
        "print(\"Best Cross-Validation Score:\", grid_search.best_score_)\n",
        "\n",
        "# Evaluate on test set\n",
        "y_pred = best_model.predict(X_test)\n",
        "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# Step 7: Save the model\n",
        "model_path = 'best_predictive_maintenance_model.joblib'\n",
        "dump(best_model, model_path)\n",
        "print(f\"Model saved to {model_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from joblib import load\n",
        "import pandas as pd\n",
        "\n",
        "# Step 8: Load the saved model\n",
        "model_path = 'best_predictive_maintenance_model.joblib'\n",
        "loaded_model = load(model_path)\n",
        "print(f\"Model loaded from {model_path}\")\n",
        "\n",
        "# Sample Data for Testing\n",
        "sample_data = pd.DataFrame({\n",
        "    'Type': [0],                    # Type 'L'\n",
        "    'Air temperature [K]': [298.9],  # Example temperature\n",
        "    'Process temperature [K]': [309.1],  # Process temperature\n",
        "    'Rotational speed [rpm]': [2861],  # Speed in rpm\n",
        "    'Torque [Nm]': [4.6],           # Torque value\n",
        "    'Tool wear [min]': [143]         # Tool wear in minutes\n",
        "})\n",
        "\n",
        "print(\"Sample Data Values:\\n\", sample_data)\n",
        "\n",
        "# Step 10: Make a prediction using the loaded model\n",
        "sample_pred = loaded_model.predict(sample_data)\n",
        "print(\"Predicted Failure Type:\", sample_pred[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SO9KGtqs86s",
        "outputId": "2e6ee170-79f6-4cce-d061-d5a828f4d0e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded from best_predictive_maintenance_model.joblib\n",
            "Sample Data Values:\n",
            "    Type  Air temperature [K]  Process temperature [K]  Rotational speed [rpm]  \\\n",
            "0     0                298.9                    309.1                    2861   \n",
            "\n",
            "   Torque [Nm]  Tool wear [min]  \n",
            "0          4.6              143  \n",
            "Predicted Failure Type: Power Failure\n"
          ]
        }
      ]
    }
  ]
}